# haiku-maker

## Project description

Haiku Maker is a system for creating haiku poems. The basic idea
of the system is to generate a batch of haiku and then evaluate
them. Picking the top scoring haiku poems, the system alters its
haiku generation. With this hopefully improved way of making haiku,
the system generates a new batch of haiku which again are evaluated.
The generator again tries to improve its generation process and the
cycle continues until the desired amount of iterations is completed.
With each iteration the system writes the top scoring haiku poems
in a text file for future inspection.

Here is a more detailed process description. The system uses 18
good haiku as a guide. These haiku are written by famous Japanese
poets. The haiku are translated into English, and even though their
syllable structure doesn't follow the typical 5-7-5 pattern, we
consider them as "ideal" haiku. Generated haiku are compared to
them in evaluation.

The system also needs to draw words from some corpus. At this point
the system only uses one text file, but if you wanted, you could
combine multiple different text files into one to emulate the
usage of multiple different texts. First each word is assigned into
a category based on its part-of-speech tag. These pos tags are
found using pos tagging function in nltk libraries. Each word's
syllable count is also counted using pronouncing library. Now
each word is assigned to a group based on its syllable count and
pos tag.

After this setup the generation can begin. The first generation
of haiku is created almost randomly. The only rule, that is always
followed, is the 5-7-5 syllable pattern. This means, that the first
line of a haiku contains 5 syllables, second one has 7, and third
has 5. A haiku is generated by picking words randomly from corpus.
If the word can be added to the current line without going over the
syllable limit, its chosen as the next word. If the word is too
long, a new one is tried until a suitable word is found. If the line
is full, we move to the next line. If the last line is filled, we
begin making a new haiku. Once the desired amount of haiku are 
generated, they are sent to the evaluator to be scored.

The evaluation was unfortunately left extremely simple. Each poem
is pos tagged like the 18 example poems. Then we find the longest
common pos tag sequence in the 18 example haiku and the haiku we
want to score. Then this number is divided by the word count of
the poem. This way we get a score between 0 and 1. If the pos
pattern matches perfectly to some example haiku the score will be 1.
Obviously this evaluation method is very simple and should be
expanded. After scoring each generated haiku, the scores are sent
back to the generator.

The generator picks some of the top scoring haiku, and makes a
Markov chain of their pos tags. It's like making a regular Markov
chain of some text, where each word is replaced by its pos tag.
The new generation of haiku is now generated using this Markov chain
(actually 2 chains, 1st and 2nd order). For each word in a haiku,
we first decide its pos tag, using Markov chains. Next, we choose
a word from that category and check if it fits on the current line
(not going over syllable limit). If there are no fitting words in
the chosen category, a new category is chosen until a suitable word
is found.

Once all haiku of this generation are generated, they are again sent
to the evaluator. These iterations are done the desired amount.
From each generation the tops scoring haiku are written in a file.
We are hoping, that the quality of haiku increases with each iteration,
and tests show that that is indeed the case. The mean score seems to
be increasing, even though some previous iteration's best haiku might
get a higher score than some later iteration's best haiku.

Some afterthoughts. This generation/evaluation cycle seems to work nicely,
but at this point the system is very simple, only considering the pos 
structures of haiku. It would have been nice to somehow check the connections
between the actual words in haiku. This way we could have maybe made
some kind of evaluation about juxtaposition, which is a traditional
trait of haiku. 

We tried to do a scoring function that would take 
subsequent word pairs into account and compare them to the word
pair occurrences in corpus text. We hoped the haiku would make more
sense if some of the word pairs appeared in the original text, but even
in the best cases only one word pair in a generated haiku appeared in
the original text. So we realized this kind of evaluation was useless.
Another way of course would be to compare these pairs into some super
large word pair database to see how many of the haiku’s word pairs are
seen in some actual existing texts. But then again if the poem is 
considered to be good if each word is only followed by a words which also
appear after it in the original text, why not use regular Markov chains.
But we didn’t want the system to be this limited, and wanted to see some
surprising word combinations. 
